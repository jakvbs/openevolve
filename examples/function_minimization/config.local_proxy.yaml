# Minimal config to run Function Minimization with a local OpenAI-compatible proxy

max_iterations: 10
checkpoint_interval: 5

llm:
  # Map of your snippet â†’ OpenEvolve fields:
  #   model  -> name
  #   base_url -> api_base
  #   api_key -> api_key
  #   provider (ignored)
  models:
    - name: "gpt-5-low"
      api_base: "http://localhost:8317/v1"
      api_key: "your-api-key-1"
      weight: 1.0
  temperature: 0.7
  max_tokens: 4096
  timeout: 120

prompt:
  system_message: "You are an expert programmer improving a function minimization algorithm. Prefer reliable global search and escaping local minima."

database:
  population_size: 30
  archive_size: 10
  num_islands: 2

evaluator:
  timeout: 60
  cascade_thresholds: [1.3]
  parallel_evaluations: 2

diff_based_evolution: true
max_code_length: 20000
